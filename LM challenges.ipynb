{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "options  = Options()\n",
    "prefs = {\n",
    "    \"translate_whitelists\":{'zh-CN':'en'},\n",
    "    \"translate\":{'enabled':'true'}\n",
    "}\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "options.add_argument('--lang=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                  Sage: 10 selenium web scraping exercises to do."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape the title and URL of the top 10 posts on the Reddit homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.reddit.com\")\n",
    "time.sleep(5)\n",
    "driver.refresh()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems encountered:\n",
    "1. i think there should be tweaks to the initial for loop, where it can skip ads and show the top 10 posts, rn its not dynamic could increase this number later if needed. news articles are also different btw, using try and except statements make me avoid this issue, would have to fix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an AD/News article, i'll fix it later, maybe :)\n",
      "This is an AD/News article, i'll fix it later, maybe :)\n"
     ]
    }
   ],
   "source": [
    "def reddit():\n",
    "    # inital attempt; this method doesnt get precise information\n",
    "    # for x in range(1, 11):\n",
    "    #     i = str(x)\n",
    "    #     slider.append(driver.find_element(By.XPATH, f'//*[@id=\"AppRouter-main-content\"]/div/div/div[2]/div[2]/div[1]/div[5]/div[{i}]').text.split('\\n'))\n",
    "\n",
    "    # first proposal isnt precise enough, would require too much text formatting\n",
    "    # the 2nd div and last div would be formmated for our for loop\n",
    "\n",
    "    userLink = 'http://www.reddit.com/user/'\n",
    "    user = [] #username and user profile link\n",
    "    postTitle = [] #title and link\n",
    "    subReddit = [] # Subreddit name\n",
    "    postLink = [] # Subreddit link\n",
    "    comments = []  #no. of comments\n",
    "\n",
    "    # post format\n",
    "    likes = [] # no. of upvotes \n",
    "    header = [] # each post has a header which contains the subreddit posted to and user who posted\n",
    "    title = [] # title of the post\n",
    "    info = [] # info in the post, could be video, text, table, etc.\n",
    "    footer = [] # contains total number of comments\n",
    "\n",
    "    for x in range(1,12):\n",
    "        i = str(x)\n",
    "        try:\n",
    "            likes.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]').text)\n",
    "            header.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[1]').text)\n",
    "            title.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[2]').text)\n",
    "            info.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[3]').text)\n",
    "            footer.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[4]').text)\n",
    "            postLink.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[2]/div[1]/a').get_attribute('href'))\n",
    "        except NoSuchElementException:\n",
    "            # try:\n",
    "            #     # if post is a news article, the format changes.\n",
    "            #     likes.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[1]').text)\n",
    "            #     header.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]/article/div[1]/div[1]').text)\n",
    "            #     title.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]/article/div[1]/div[2]').text)\n",
    "            #     # get info if link available\n",
    "            #     info.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]/article/div[1]/div[3]').text)\n",
    "            #     footer.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]/div').text)\n",
    "            #     postLink.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]/article/div[1]/div[2]/div[1]/a').get_attribute('href'))\n",
    "\n",
    "            # except NoSuchElementException:\n",
    "            print(\"This is an AD/News article, i'll fix it later, maybe :)\")\n",
    "            pass\n",
    "\n",
    "    # print(len(header))\n",
    "    # while len(header)<11:\n",
    "    #     i = str(len(header)+1)\n",
    "    #     try:\n",
    "    #         likes.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[2]').text)\n",
    "    #         header.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[1]').text)\n",
    "    #         title.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[2]').text)\n",
    "    #         info.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[3]').text)\n",
    "    #         footer.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[4]').text)\n",
    "    #         postLink.append(driver.find_element(By.XPATH, f'//div[5]/div[{i}]/div/div/div[3]/div[2]/div[1]/a').get_attribute('href'))\n",
    "    #     except NoSuchElementException:\n",
    "    #         print('This is an AD')\n",
    "    #         pass\n",
    "        \n",
    "    for x in range(len(header)-1):\n",
    "        user.append(header[x].split('\\n')[2] + ' : '+ userLink+header[x].split('\\n')[2][2:])\n",
    "        postTitle.append(title[x] + ' : ' + postLink[x])\n",
    "        subReddit.append(header[x].split('\\n')[0])\n",
    "        comments.append(footer[x].split(' ')[0])\n",
    "    \n",
    "    setattr(reddit, 'user', user)\n",
    "    setattr(reddit, 'postTitle' , postTitle) \n",
    "    setattr(reddit, 'comments', comments)  \n",
    "    setattr(reddit, 'likes',likes) \n",
    "\n",
    "\n",
    "reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u/killHACKS : http://www.reddit.com/user/killHACKS',\n",
       " 'u/dobbyisafreepup : http://www.reddit.com/user/dobbyisafreepup',\n",
       " 'u/SeXyHuNtEr69420 : http://www.reddit.com/user/SeXyHuNtEr69420',\n",
       " 'u/IvorBrett : http://www.reddit.com/user/IvorBrett',\n",
       " 'u/SpicyThunder335 : http://www.reddit.com/user/SpicyThunder335',\n",
       " 'u/stache914 : http://www.reddit.com/user/stache914',\n",
       " 'u/Ahomelessfish : http://www.reddit.com/user/Ahomelessfish',\n",
       " 'u/Suajj : http://www.reddit.com/user/Suajj']"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reddit is killing third-party applications (and itself). Read more in the comments. : https://www.reddit.com/r/LifeProTips/comments/148wweh/reddit_is_killing_thirdparty_applications_and/',\n",
       " 'Ok Faux News\\nClubhouse : https://www.reddit.com/r/WhitePeopleTwitter/comments/148vp4m/ok_faux_news/',\n",
       " \"What is your secret that you can't tell anyone because it will probably ruin your life? : https://www.reddit.com/r/AskReddit/comments/148b059/what_is_your_secret_that_you_cant_tell_anyone/\",\n",
       " 'Sheep getting vaccinated : https://www.reddit.com/r/thisismylifenow/comments/148ucw7/sheep_getting_vaccinated/',\n",
       " 'Indefinite Blackout: Next Steps, Polling Your Community, and Where We Go From Here : https://www.reddit.com/r/ModCoord/comments/148ks6u/indefinite_blackout_next_steps_polling_your/',\n",
       " 'Well at least he got cake….\\nMichael jacksons lost sextapes : https://www.reddit.com/r/discordVideos/comments/148vobo/well_at_least_he_got_cake/',\n",
       " 'Can you truly forgive a partner after cheating? : https://www.reddit.com/r/ask/comments/148gtxw/can_you_truly_forgive_a_partner_after_cheating/',\n",
       " '??? : https://www.reddit.com/r/Tinder/comments/148xt57/_/']"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.postTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1.1k', '21.4k', '1.7k', '9.9k', '326', '8.9k', '362']"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24.3k',\n",
       " 'r/politics\\n•Posted by\\nu/Picture-unrelated\\n9 hours ago\\nAOC says idea Trump is victim of a ‘two-tier’ justice system is an insult to Black and brown Americans\\nindependent.co.uk/news/w...\\nJoin\\n714 Comments\\nShare\\nSave',\n",
       " '33.0k',\n",
       " '23.7k',\n",
       " '37.6k',\n",
       " '15.1k',\n",
       " '12.0k',\n",
       " '6.3k',\n",
       " '5.5k',\n",
       " '4.8k']"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reddit.com/r/ask/comments/148gtxw/can_you_truly_forgive_a_partner_after_cheating/'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i=\"3\"\n",
    "# /html/body/div[1]/div/div[2]/div[2]/div/div/div/div[2]/div[2]/div[1]/div[5]/div[1]/div/div/div[3]/div[3]/div/div[2]/div\n",
    "# /html/body/div[1]/div/div[2]/div[2]/div/div/div/div[2]/div[2]/div[1]/div[5]/div[3]/div/div/div[3]/div[2]/div[1]/a\n",
    "# /html/body/div[1]/div/div[2]/div[2]/div/div/div/div[2]/div[2]/div[1]/div[5]/div[4]/div/div/div[3]/div[3]/a\n",
    "\n",
    "driver.find_element(By.XPATH, '//div[5]/div[4]/div/div/div[3]/div[2]/div[1]/a').get_attribute('href')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18.3k'"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element(By.XPATH, '//div[5]/div[2]/div/div/div[1]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Promoted' in driver.find_element(By.XPATH, '//div[5]/div[14]/div/div/div/div[3]/div/div[1]/div').text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrape the current weather conditions (temperature, humidity, wind speed, etc.) for a specific location from a weather website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.wunderground.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(city):\n",
    "    return city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'shenyang'\n",
    "search = driver.find_element(By.XPATH, '//div/div/lib-search/div/div/div/input')\n",
    "search.send_keys(city)\n",
    "time.sleep(3)\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date, time, currtemp, sun \n",
    "tdyForecast = []\n",
    "# date, time, sun, forecast text and precipitation\n",
    "tnForecast = []\n",
    "# list would contain the celsius equivalent of the currTemp, tonight, tomorrow and tomorrow night\n",
    "Cel = []\n",
    "# current feel of the temperature on the body  \n",
    "feelsLike = ''\n",
    "# tomorrow forecast; would contain date, temp, forecast text and precipitation\n",
    "tmrForecast = []\n",
    "# tomorrow night's forecast; would contain date, temp, forecast text and precipitation\n",
    "tmrNightForecast = []\n",
    "# precipitation, pollen in air, air quality, UV index, pressure, visibility, clouds, humidity\n",
    "others = []\n",
    "# sunrise, sunset, length of day\n",
    "astronomy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['access_time 12:53 PM CST on June 24, 2023 (GMT +8) | Updated just now',\n",
       " '94° | 68°',\n",
       " '94 °F',\n",
       " 'LIKE 97°',\n",
       " 'Fair',\n",
       " 'N',\n",
       " '16',\n",
       " \"Today's temperature is forecast to be NEARLY THE SAME as yesterday.\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element(By.XPATH, '//div/section/div[3]/div[1]/div/div[1]/div[1]').text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function that collects all data about today's weather. day n nite\n",
    "def today():\n",
    "    forecast = driver.find_element(By.XPATH, '//div/section/div[3]/div[1]/div/div[1]/div[1]').text.split('\\n')\n",
    "    others = driver.find_element(By.XPATH, '//lib-additional-conditions/lib-item-box/div/div[2]').text.split('\\n')\n",
    "    cityName = driver.find_element(By.XPATH, '//lib-city-header/div[1]/div/h1').text.split(' Weather Conditions')[0]\n",
    "    aq = driver.find_element(By.XPATH, '//*[@id=\"inner-content\"]/div[3]/div[1]/div/div[4]/div[3]').text.split('\\n')\n",
    "    clouds = forecast[4].lower()+'ly cloudy skies'\n",
    "    humidity = others[8:10]\n",
    "    \n",
    "    \n",
    "    # date and time\n",
    "    time = forecast[0].split('access_time ')[1].split(' | ')[0]\n",
    "    date = forecast[0].split('access_time ')[1].split(' | ')[0].split(' on ')[1]\n",
    "    \n",
    "    # highs and lows\n",
    "    h = driver.find_element(By.XPATH, '//lib-almanac/div/div[2]/div[4]').text.split('\\n')[1].split(' ')[0]\n",
    "    l = driver.find_element(By.XPATH, '//lib-almanac/div/div[2]/div[5]').text.split('\\n')[1].split(' ')[0]\n",
    "    # highlow = []\n",
    "    highF = l + \" to \" + h\n",
    "    highC = str((int(l) - 32) * 0.556)[:2] + \" to \" + str((int(h) - 32) * 0.556)[:2]\n",
    "    # highlow.append(highC, highF)\n",
    "    \n",
    "    # current temperature, conversions from fahrenheit to celsius\n",
    "    f = int(forecast[2].split(' ')[0])\n",
    "    c = str(int((f - 32) * (0.556))) + ' °C'\n",
    "    temp = []\n",
    "    temp.append(c)\n",
    "    temp.append(forecast[2])\n",
    "    \n",
    "    # feels like\n",
    "    feelsLike = []\n",
    "    feelsC = \"Today's weather feels like \" + str((int(forecast[3].split('°')[0][-2:]) - 32) * 0.556)[:2] + ' °C'\n",
    "    feelsF = \"Today's weather feels like \" + forecast[3][-2:] + ' F'\n",
    "    feelsLike.append(feelsC)\n",
    "    feelsLike.append(feelsF)\n",
    "    \n",
    "    line1 = f\"Good morning/afternoon/evening, and welcome to the weather report for {cityName} for today, {date}.\"\n",
    "    line2 = f\"{cityName} is currently experiencing mostly {clouds} throughout the day. Temperatures are expected to range between {highC} degrees Celsius ({highF} degrees Fahrenheit), with a relative humidity of around {humidity[1]}.\"\n",
    "    line3 = f\"If you're planning to be out and about today, make sure to bring an umbrella or raincoat as there is a high chance of rain throughout the day. The air quality in {cityName.split(',')[0]} is {aq[1].lower()}, with a PM2.5 index of around {aq[3]}.\"\n",
    "    # line4 = f\"Looking ahead, the forecast for the next few days in Chengdu calls for a mix of cloudy and sunny skies with scattered thunderstorms, and temperatures in the low to mid 30s Celsius (mid to upper 80s Fahrenheit).\"\n",
    "    line5 = f\"That's your weather report for {cityName} for today. Stay safe and dry out there!\"\n",
    "    \n",
    "    # weatherReport = line1 + \"\\n + line2 + \"\\n\" + line3 + \"\\n\" + line5\n",
    "    \n",
    "    return line1, line2, line3, line5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Good morning/afternoon/evening, and welcome to the weather report for Shenyang, Liaoning, People's Republic of China for today, June 24, 2023 (GMT +8).\",\n",
       " \"Shenyang, Liaoning, People's Republic of China is currently experiencing mostly fairly cloudy skies throughout the day. Temperatures are expected to range between 20 to 34 degrees Celsius (69 to 94 degrees Fahrenheit), with a relative humidity of around 43 %.\",\n",
       " \"If you're planning to be out and about today, make sure to bring an umbrella or raincoat as there is a high chance of rain throughout the day. The air quality in Shenyang is good, with a PM2.5 index of around 52.\",\n",
       " \"That's your weather report for Shenyang, Liaoning, People's Republic of China for today. Stay safe and dry out there!\")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AIR QUALITY', 'Good', 'Air Quality Index', '52', 'Air Quality tile']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element(By.XPATH, '//*[@id=\"inner-content\"]/div[3]/div[1]/div/div[4]/div[3]').text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June 24, 2023 (GMT +8)'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date,time, currtemp, today low/high and sun\n",
    "driver.find_element(By.XPATH, '//div/section/div[3]/div[1]/div/div[1]/div[1]').text.split('\\n')[0].split('access_time ')[1].split(' | ')[0].split(' on ')[1]\n",
    "# currtemp fahrenheit n celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'69'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temp conversions\n",
    "driver.find_element(By.XPATH, '//lib-almanac/div/div[2]/div[5]').text.split('\\n')[1].split(' ')[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scrape the product details (name, price, image, description, etc.) from an eCommerce website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scrape the lyrics of your favorite songs from a music website.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Scrape the list of trending topics on Twitter and the number of tweets associated with each topic.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Scrape the list of all the restaurants in a particular city from Yelp."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Scrape the list of all the books in a particular category from Amazon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Scrape the list of all the movies in a particular genre from IMDB."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Scrape the list of all the jobs posted on a job search website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Scrape the list of all the headlines from a news website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
